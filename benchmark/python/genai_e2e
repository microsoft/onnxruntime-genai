[
    {
        "config": {
            "backend": "onnxruntime-genai",
            "batch_size": 2.0,
            "precision": "fp16",
            "warmup_runs": 1,
            "measured_runs": 10,
            "model_info": {
                "full_name": "model_name"
            },
            "prompt_length": 16.0,
            "tokens_generated": 256.0,
            "max_length": 272.0
        },
        "metadata": {
            "device": "cpu",
            "package_name": "onnxruntime-genai-cuda",
            "package_version": "0.5.0"
        },
        "metrics": {
            "tokenization_throughput_tps": 58840.143150801494,
            "tokenization_latency_ms": 0.5438463995233178,
            "prompt_processing_throughput_tps": 93.1784820448208,
            "prompt_processing_latency_ms": 21.464183104399126,
            "token_generation_throughput_tps": 23.878914843793623,
            "token_generation_latency_ms": 83.75589984231719,
            "sampling_throughput_tps": 619.8194285574921,
            "sampling_latency_ms": 3.226746222935617,
            "wall_clock_throughput_tps": 25.05183192022546,
            "wall_clock_time_s": 21.714978837966918
        },
        "trigger_date": "2024-12-04 13:42:49"
    }
]